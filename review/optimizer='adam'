딥러닝에서 optimizer은 학습속도를 빠르고 안정적이게 하는 것

경사하강법은 1차 근삿값 발견용 최적화 알고리즘
>>함수의 기울기를 구하여 기울기가 낮은 쪽으로 계속 이동시켜서 극값에 이를때까지 반복
>>기울기에 알파(학습률)를 곱해서 이동
>>알파가 너무 커도 좋지 않고 작아도 좋지 않다.
>>볼록함수를 기반으로 볼록함수는 어디서 시작하더라도 경사 하강법으로 최적값에 도달할 수 있다. 
